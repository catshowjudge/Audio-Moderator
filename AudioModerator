{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AudioModerator","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMav8L4ob1SmzG0aVpwKFq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v9w1pfxw_Q_1","colab_type":"code","outputId":"5ca92287-891f-45c9-8478-33041961952c","executionInfo":{"status":"ok","timestamp":1591750347580,"user_tz":420,"elapsed":1664,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","# from pickle import load\n","# from pickle import dump\n","# from numpy.random import rand\n","# from numpy.random import shuffle\n"," \n","import warnings\n","warnings.simplefilter('ignore')\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import string \n","import re \n","\n","#import tensorflow as tf\n","import keras\n","from keras.models import Sequential \n","from keras.layers import Dense, LSTM, Embedding, RepeatVector, Flatten, TimeDistributed\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import ModelCheckpoint \n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import load_model \n","from keras import optimizers \n","\n","import jieba\n","#documentation\n","#https://github.com/fxsjy/jieba\n","\n","#other Chinese preprocessing\n","#import spacy\n","#import zh_core_web_sm\n","#import HanLP\n","#import snownlp\n","\n","#style elements, hide warnings\n","plt.style.use('ggplot')\n","%matplotlib inline\n","print('done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1rOqEa8B-DWW","colab_type":"code","outputId":"2b98f5ca-c37c-440f-d600-e96927fb36e0","executionInfo":{"status":"ok","timestamp":1591750350649,"user_tz":420,"elapsed":520,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, mode='rt', encoding='utf-8')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n","\n","doc = load_doc('Bi-Spoken.txt')\n","sents = doc.split('\\n')\n","sents[:2]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['How do you think of your proficiency in written and spoken English?',\n"," '你认为你的书面英语和口语熟练程度如何？']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"-wKrxU3jFgc8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqO-4tJO_RDE","colab_type":"code","outputId":"da229087-f54b-4bb4-a668-af7f01908c5f","executionInfo":{"status":"ok","timestamp":1591750354491,"user_tz":420,"elapsed":336,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["zh_data = sents[1::2]\n","en_data = sents[::2]\n","del en_data[-1]\n","print(en_data[-3:])\n","print(zh_data[-3:])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[\"If you go now, you're likely to hit the rush hour.\", 'Cars often pile up here in the rush hours.', 'The cavaliers rushed into the palace to protect the king.']\n","['你要是现在走， 可能正赶上交通拥挤的时刻.', '在交通拥挤时刻汽车往往在这里挤成一团。', '武士们冲进宫里保护国王。']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UG1Y081W_RJk","colab_type":"code","outputId":"75ce8352-3d82-41bc-98ec-ae4c0446b589","executionInfo":{"status":"ok","timestamp":1591750356843,"user_tz":420,"elapsed":1061,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["en_short = en_data[:1000]\n","zh_short = zh_data[:1000]\n","en_short_segs = []\n","zh_short_segs = []\n","\n","for i in en_short: \n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", i)\n","  en_short_segs.append(w)\n","for i in zh_short:\n","  zh_short_seg_list = jieba.cut(i, cut_all=False)\n","  segs_short = \" \".join(zh_short_seg_list)\n","  zh_short_segs.append(segs_short)\n","\n","zh_short_segs[:5]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.610 seconds.\n","Prefix dict has been built successfully.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['你 认为 你 的 书面 英语 和 口语 熟练程度 如何 ？',\n"," '她 的 英语口语 不是 十分 好 ， 可 她 的 意思 可以 理解 得 很 清楚 。',\n"," '天空 中飘着 几朵 云 ， 但 阳光灿烂 。',\n"," '我 和 妻子 沿 河岸 走 着 。',\n"," '萨姆 ： 你 打算 如何 处理 那共瓶 ？']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"n5XIJvse_RRI","colab_type":"code","outputId":"ac308219-7e70-4b1a-9387-f8db642a37bc","executionInfo":{"status":"ok","timestamp":1591750358456,"user_tz":420,"elapsed":390,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","\ttokenizer = Tokenizer()\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer\n","\n","# max sentence length\n","def max_length(lines):\n","\treturn max(len(line.split()) for line in lines)\n"," \n","# prepare english tokenizer\n","en_tokenizer = create_tokenizer(en_short_segs)\n","en_vocab_size = len(en_tokenizer.word_index) + 1\n","en_length = max_length(en_short_segs)\n","print('English Vocabulary Size: %d' % en_vocab_size)\n","print('English Max Length: %d' % (en_length))\n","# prepare chinese tokenizer\n","zh_tokenizer = create_tokenizer(zh_short_segs)\n","zh_vocab_size = len(zh_tokenizer.word_index) + 1\n","zh_length = max_length(zh_short_segs)\n","print('Chinese Vocabulary Size: %d' % zh_vocab_size)\n","print('Chinese Max Length: %d' % (zh_length))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["English Vocabulary Size: 3779\n","English Max Length: 61\n","Chinese Vocabulary Size: 4938\n","Chinese Max Length: 52\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RYHcfbgMPNgX","colab_type":"code","outputId":"9eb7126c-5433-4e2a-9663-90a0934d6ac8","executionInfo":{"status":"ok","timestamp":1591750359612,"user_tz":420,"elapsed":377,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["en_sequences = en_tokenizer.texts_to_sequences(en_short_segs)\n","print(en_sequences[:5])\n","zh_sequences = zh_tokenizer.texts_to_sequences(zh_short_segs)\n","print(zh_sequences[:5])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[116, 62, 31, 357, 4, 117, 1660, 6, 302, 5, 1026, 358], [52, 1026, 358, 16, 32, 72, 152, 21, 52, 1027, 1028, 128, 359, 554], [40, 35, 91, 1029, 6, 1, 724, 21, 1, 555, 16, 1661], [44, 166, 5, 17, 35, 556, 303, 1, 1662, 4, 1, 1030], [557, 81, 35, 31, 183, 2, 62, 23, 8, 1663, 1031]]\n","[[22, 113, 22, 2, 1852, 746, 32, 1853, 1854, 179, 97], [21, 2, 1855, 264, 180, 265, 1, 143, 21, 2, 1856, 35, 747, 70, 56, 1095, 3], [1096, 1857, 1858, 1859, 1, 13, 1097, 3], [8, 32, 114, 1860, 1098, 144, 28, 3], [748, 38, 22, 266, 179, 1861, 1862, 97]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EcywtAUi_Raq","colab_type":"code","colab":{}},"source":["\n","# encode and pad sequences\n","def encode_sequences(tokenizer, length, lines):\n","\t# integer encode sequences\n","\tX = tokenizer.texts_to_sequences(lines)\n","\t# pad sequences with 0 values\n","\tX = pad_sequences(X, maxlen=length, padding='post')\n","\treturn X"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AOkuzD7f_Rii","colab_type":"code","colab":{}},"source":["\n","# one hot encode target sequence\n","def encode_output(sequences, vocab_size):\n","\tylist = list()\n","\tfor sequence in sequences:\n","\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n","\t\tylist.append(encoded)\n","\ty = np.array(ylist)\n","\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n","\treturn y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ta_2gpSU_Rlv","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(zh_short_segs, en_short_segs, test_size=0.2,random_state= 12)\n","\n","# prepare training data\n","trainX = encode_sequences(zh_tokenizer, zh_length, X_train)\n","trainY = encode_sequences(en_tokenizer, en_length, y_train)\n","trainY = encode_output(trainY, en_vocab_size)\n","# prepare validation data\n","testX = encode_sequences(zh_tokenizer, zh_length, X_test)\n","testY = encode_sequences(en_tokenizer, en_length, y_test)\n","testY = encode_output(testY, en_vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMZ6afTbiHsU","colab_type":"code","outputId":"48c3ea17-3a22-4ad1-fdb5-707e1928fa2c","executionInfo":{"status":"ok","timestamp":1591750365127,"user_tz":420,"elapsed":363,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["print(trainX[0])\n","print(trainY[0])\n","print(testX[0])\n","print(testY[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[  16    8   29  108   17    1    8 1954   40    1   16 1102 1130   24\n","    4  150  560 1955    4    1   13    8   58  181  164  310  118   17\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]]\n","[ 102    6   15  284 3331 3332    1   13   73  402  289    1  115  175\n"," 3333 3334    3    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0]\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]\n"," [1. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tIAJp4mL_RuF","colab_type":"code","outputId":"b32d4d9e-2eb7-4ff9-ba1e-af919c681dde","executionInfo":{"status":"ok","timestamp":1591750367294,"user_tz":420,"elapsed":1389,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["\n","# define NMT model\n","def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n","\tmodel = Sequential()\n","\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n","\tmodel.add(LSTM(n_units))\n","\tmodel.add(RepeatVector(tar_timesteps))\n","\tmodel.add(LSTM(n_units, return_sequences=True))\n","\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n","\treturn model\n"," \n","# define model\n","model = define_model(zh_vocab_size, en_vocab_size, zh_length, en_length, 256)\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","# summarize defined model\n","print(model.summary())\n","#plot_model(model, to_file='model.png', show_shapes=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 52, 256)           1264128   \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","repeat_vector_1 (RepeatVecto (None, 61, 256)           0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 61, 256)           525312    \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, 61, 3779)          971203    \n","=================================================================\n","Total params: 3,285,955\n","Trainable params: 3,285,955\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yCnYCifC_R0P","colab_type":"code","outputId":"662cbdf8-d74d-4d40-c62f-e070ed41b2c3","executionInfo":{"status":"ok","timestamp":1591750438673,"user_tz":420,"elapsed":70731,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["filename = 'model.h5'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","history = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), \n","          callbacks=[checkpoint], verbose=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 800 samples, validate on 200 samples\n","Epoch 1/20\n"," - 4s - loss: 6.4898 - val_loss: 2.9034\n","\n","Epoch 00001: val_loss improved from inf to 2.90340, saving model to model.h5\n","Epoch 2/20\n"," - 3s - loss: 2.6640 - val_loss: 2.6582\n","\n","Epoch 00002: val_loss improved from 2.90340 to 2.65818, saving model to model.h5\n","Epoch 3/20\n"," - 3s - loss: 2.6095 - val_loss: 2.5839\n","\n","Epoch 00003: val_loss improved from 2.65818 to 2.58391, saving model to model.h5\n","Epoch 4/20\n"," - 3s - loss: 2.4599 - val_loss: 2.4423\n","\n","Epoch 00004: val_loss improved from 2.58391 to 2.44229, saving model to model.h5\n","Epoch 5/20\n"," - 3s - loss: 2.3354 - val_loss: 2.3354\n","\n","Epoch 00005: val_loss improved from 2.44229 to 2.33538, saving model to model.h5\n","Epoch 6/20\n"," - 3s - loss: 2.2472 - val_loss: 2.2709\n","\n","Epoch 00006: val_loss improved from 2.33538 to 2.27086, saving model to model.h5\n","Epoch 7/20\n"," - 3s - loss: 2.2042 - val_loss: 2.2679\n","\n","Epoch 00007: val_loss improved from 2.27086 to 2.26790, saving model to model.h5\n","Epoch 8/20\n"," - 3s - loss: 2.1781 - val_loss: 2.2355\n","\n","Epoch 00008: val_loss improved from 2.26790 to 2.23553, saving model to model.h5\n","Epoch 9/20\n"," - 3s - loss: 2.1606 - val_loss: 2.2316\n","\n","Epoch 00009: val_loss improved from 2.23553 to 2.23155, saving model to model.h5\n","Epoch 10/20\n"," - 3s - loss: 2.1614 - val_loss: 2.2333\n","\n","Epoch 00010: val_loss did not improve from 2.23155\n","Epoch 11/20\n"," - 3s - loss: 2.1511 - val_loss: 2.2327\n","\n","Epoch 00011: val_loss did not improve from 2.23155\n","Epoch 12/20\n"," - 3s - loss: 2.1450 - val_loss: 2.2366\n","\n","Epoch 00012: val_loss did not improve from 2.23155\n","Epoch 13/20\n"," - 3s - loss: 2.1608 - val_loss: 2.2332\n","\n","Epoch 00013: val_loss did not improve from 2.23155\n","Epoch 14/20\n"," - 3s - loss: 2.1551 - val_loss: 2.2396\n","\n","Epoch 00014: val_loss did not improve from 2.23155\n","Epoch 15/20\n"," - 3s - loss: 2.1558 - val_loss: 2.2363\n","\n","Epoch 00015: val_loss did not improve from 2.23155\n","Epoch 16/20\n"," - 3s - loss: 2.1723 - val_loss: 2.2348\n","\n","Epoch 00016: val_loss did not improve from 2.23155\n","Epoch 17/20\n"," - 3s - loss: 2.1942 - val_loss: 2.2293\n","\n","Epoch 00017: val_loss improved from 2.23155 to 2.22930, saving model to model.h5\n","Epoch 18/20\n"," - 3s - loss: 2.1602 - val_loss: 2.2890\n","\n","Epoch 00018: val_loss did not improve from 2.22930\n","Epoch 19/20\n"," - 3s - loss: 2.1294 - val_loss: 2.2158\n","\n","Epoch 00019: val_loss improved from 2.22930 to 2.21578, saving model to model.h5\n","Epoch 20/20\n"," - 3s - loss: 2.0706 - val_loss: 2.2337\n","\n","Epoch 00020: val_loss did not improve from 2.21578\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ib3EJpQ5_R6M","colab_type":"code","outputId":"2b0825ca-ea5f-4fb3-f6ed-2714f6b1af44","executionInfo":{"status":"ok","timestamp":1591750443511,"user_tz":420,"elapsed":383,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.plot(history.history['loss']) \n","plt.plot(history.history['val_loss']) \n","plt.legend(['train','validation']) \n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OxMcYKjz_R_x","colab_type":"code","colab":{}},"source":["\n","# load model\n","model = load_model('model.h5')\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hMtBwRnAj3RD","colab_type":"code","outputId":"d0fdf492-f66d-41cf-d686-f75730dfb317","executionInfo":{"status":"ok","timestamp":1591751294322,"user_tz":420,"elapsed":707,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["translation = model.predict_classes(testX, verbose=0)\n","translation[:2]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"XPpxXYcJ_SDi","colab_type":"code","colab":{}},"source":["\n","# map an integer to a word\n","def word_for_id(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8EfnVmgo_SLv","colab_type":"code","colab":{}},"source":["\n","# generate target given source sequence\n","def predict_sequence(model, tokenizer, source):  #encode sequence(source, tokenizer, lines) def encode_sequences(tokenizer, length, lines):\n","\tprediction = model.predict_classes(source, verbose=0)[0]\n","\tintegers = [np.argmax(vector) for vector in prediction]\n","\ttarget = list()\n","\tfor i in integers:\n","\t\tword = word_for_id(i, tokenizer)\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\ttarget.append(word)\n","\treturn ' '.join(target)\n","\n","\n","# def predict_sequence(model, tokenizer, encode_sequences(tokenizer, length, lines)):\n","# \tprediction = model.predict_classes(source, verbose=0)[0]\n","# \tintegers = [np.argmax(vector) for vector in prediction]\n","# \ttarget = list()\n","# \tfor i in integers:\n","# \t\tword = word_for_id(i, tokenizer)\n","# \t\tif word is None:\n","# \t\t\tbreak\n","# \t\ttarget.append(word)\n","# \treturn ' '.join(target)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hbnAV0o0G2p","colab_type":"code","outputId":"d427f77d-501d-40e9-97a2-46e01b69ab5c","executionInfo":{"status":"error","timestamp":1591752073908,"user_tz":420,"elapsed":885,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":327}},"source":["encode_sequences(zh_tokenizer, zh_length, testX[1])"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-eae44a1e08f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-c4e5b78b65ad>\u001b[0m in \u001b[0;36mencode_sequences\u001b[0;34m(tokenizer, length, lines)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# integer encode sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# pad sequences with 0 values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                                             self.split)\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(text, filters, lower, split)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.int32' object has no attribute 'lower'"]}]},{"cell_type":"code","metadata":{"id":"8Hl-4jv30foV","colab_type":"code","outputId":"0b69616d-2cc7-4d66-ea85-32d5ac0a30ef","executionInfo":{"status":"ok","timestamp":1591752149324,"user_tz":420,"elapsed":823,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["testX[1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1055,  739,    1,    9,  112,   10, 4464, 1740, 4465,   12,    2,\n","        127,  207,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"ozNFT64i_SOp","colab_type":"code","outputId":"00766732-058e-4282-98e5-b4937813e31f","executionInfo":{"status":"error","timestamp":1591752555678,"user_tz":420,"elapsed":512,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":344}},"source":["translations1 = predict_sequence(model, en_tokenizer, testX[1])\n","translations1[:50]"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-fb882feee983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslations1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtranslations1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-69d7d70eafa1>\u001b[0m in \u001b[0;36mpredict_sequence\u001b[0;34m(model, tokenizer, source)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# generate target given source sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#encode sequence(source, tokenizer, lines) def encode_sequences(tokenizer, length, lines):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mintegers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have shape (52,) but got array with shape (1,)"]}]},{"cell_type":"code","metadata":{"id":"p7fjChlzxwoO","colab_type":"code","outputId":"ab0d8cdb-a0fe-454a-b166-5a007c215110","executionInfo":{"status":"ok","timestamp":1591751485384,"user_tz":420,"elapsed":608,"user":{"displayName":"Kelsey Seymour","photoUrl":"","userId":"07931473340689515868"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["testX"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 102,    6,   15, ...,    0,    0,    0],\n","       [1055,  739,    1, ...,    0,    0,    0],\n","       [ 687, 4216,   32, ...,    0,    0,    0],\n","       ...,\n","       [  21,  277, 1184, ...,    0,    0,    0],\n","       [ 748,   38,   22, ...,    0,    0,    0],\n","       [ 554,  246,    1, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"XOjRh7To_SXo","colab_type":"code","colab":{}},"source":["\n","# evaluate the skill of the model\n","def evaluate_model(model, tokenizer, sources, raw_dataset):\n","\tactual, predicted = list(), list()\n","\tfor i, source in enumerate(sources):\n","\t\t# translate encoded source text\n","\t\tsource = source.reshape((1, source.shape[0]))\n","\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n","\t\traw_target, raw_src = raw_dataset[i]\n","\t\tif i < 10:\n","\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n","\t\tactual.append([raw_target.split()])\n","\t\tpredicted.append(translation.split())\n","\t# calculate BLEU score\n","\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n","\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n","\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUkGbKc0_Sbo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1RYcYp-_SUs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NglEhyfN_SSc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRkFwANk_SJn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRYF5pJ7_SG7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUn34TKk_R9W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEwoNALP_R3_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vjecGz5w_Rx0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjYLog-D_Rrv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CamX-BHc_RpO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PPVcoCm_Rgf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lW_C1zZ9_Rea","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9Dts0zH_RYT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaI-azGH_RU0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDNG7W5z_ROM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zheAXvLC_RL0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WMlaTW2_RG_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}